{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2\n",
    "## Name: Â∏∏Èë´Á£ä\n",
    "## ID:1801212779"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Implement a function closed_form_1 that computes this closed form solution given the features ùêó, labels Y (using Python or Matlab).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv(\"climate_change_1.csv\",header = 0)\n",
    "df_2 = pd.read_csv(\"climate_change_2.csv\",header = 0)\n",
    "training_set = df_1[df_1.Year<=2006]\n",
    "testing_set = df_1[df_1.Year>=2006]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(training_set)\n",
    "Y=training_set.values[:,-1]\n",
    "constant = np.ones(n_samples)\n",
    "X=np.insert(training_set.values[:,2:-1],0,constant,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.24594261e+02,  6.42053134e-02,  6.45735927e-03,  1.24041896e-04,\n",
       "       -1.65280033e-02, -6.63048889e-03,  3.80810324e-03,  9.31410838e-02,\n",
       "       -1.53761324e+00])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def closed_form_1(x,y):\n",
    "    beta = np.linalg.inv(x.T@x)@x.T@y\n",
    "    return beta\n",
    "\n",
    "beta = closed_form_1(X,Y)\n",
    "beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Write down the mathematical formula for the linear model and evaluate the model R2 on the training set and the testing set.\n",
    "The mathematical formula for the linear model is\n",
    "* $$y=X\\beta+\\epsilon$$\n",
    "\n",
    "The formula of $R^2$ is\n",
    "* $$R^2 = \\frac{\\Sigma_i(\\hat y_i-\\bar y_i)^2}{\\Sigma_i(y_i-\\bar y_i)^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7508932772525233"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def R_squared(x,y,beta):\n",
    "    SSR = np.var(x@beta)*len(x)\n",
    "    SST = np.var(y)*len(x)\n",
    "    return SSR/SST\n",
    "\n",
    "R_squared(X,Y,closed_form_1(X,Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_squared of training_data is 0.7508932772525233\n",
      "R_squared of testing_data is 0.25042289711229276\n"
     ]
    }
   ],
   "source": [
    "n_samples = len(testing_set)\n",
    "Y_test=testing_set.values[:,-1]\n",
    "constant = np.ones(n_samples)\n",
    "X_test=np.insert(testing_set.values[:,2:-1],0,constant,axis=1)\n",
    "\n",
    "R_squared(X_test,Y_test,closed_form_1(X,Y))\n",
    "\n",
    "print(\"R_squared of training_data is\", R_squared(X,Y,closed_form_1(X,Y)))\n",
    "print(\"R_squared of testing_data is\", R_squared(X_test,Y_test,closed_form_1(X,Y)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Which variables are significant in the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_test(x,y):\n",
    "    sum_error = (y-x@closed_form_1(x,y)).T@(y-x@closed_form_1(x,y))\n",
    "    n = np.shape(x)[0]\n",
    "    k = np.shape(x)[1]\n",
    "    var_beta = sum_error/(n-k)*np.diag(np.linalg.inv(X.T@X))\n",
    "    t = closed_form_1(x,y)/np.sqrt(var_beta)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.26517396,  9.923226  ,  2.8264197 ,  0.2404694 , -1.92972604,\n",
       "       -4.07783387,  3.75729271,  6.31256095, -7.21030085])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_test(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False,  True,  True,  True, False, False,  True])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_test(X,Y)<2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Please write down the loss function for linear model with L1 regularization, L2 regularization, respectively.\n",
    "* The loss function with $L_1$ regularization $$L=(Y-X\\beta)'(Y-X\\beta)+\\lambda||\\beta||_1$$\n",
    "* The loss function with $L_2$ regularization $$L=(Y-X\\beta)'(Y-X\\beta)+\\lambda ||\\beta||_2^2$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.The closed form solution for linear model with L2 regularization:\n",
    "$$\\theta = (X^TX+\\lambda I)^{-1}X^TY$$ \n",
    "### where I is the identity matrix. Write a function closed_form_2 that computes this closed form solution given the features X, labels Y and the regularization parameter $\\lambda$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.08439685e+01,  4.48393633e-02,  8.41756269e-03,  2.58313240e-04,\n",
       "       -1.76472998e-02, -6.80438552e-03,  3.74782755e-03,  6.07197938e-02,\n",
       "       -2.68981314e-02])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def closed_form_2(x,y,lam):\n",
    "    lam_mat = lam*np.eye(x.shape[1])\n",
    "    lam_mat[0,0] = 0\n",
    "    beta = np.linalg.inv(x.T@x+lam_mat)@x.T@y\n",
    "    return beta\n",
    "\n",
    "closed_form_2(X,Y,10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Compare the two solutions in problem 1 and problem 2 and explain the reason why linear model with L2 regularization is robust. (using climate_change_1.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 coeffcient: [-8.08439685e+01  4.48393633e-02  8.41756269e-03  2.58313240e-04\n",
      " -1.76472998e-02 -6.80438552e-03  3.74782755e-03  6.07197938e-02\n",
      " -2.68981314e-02]\n",
      "no punishment coefficient: [-1.24594261e+02  6.42053134e-02  6.45735927e-03  1.24041896e-04\n",
      " -1.65280033e-02 -6.63048889e-03  3.80810324e-03  9.31410838e-02\n",
      " -1.53761324e+00]\n"
     ]
    }
   ],
   "source": [
    "beta_L2 = closed_form_2(X,Y,10)\n",
    "beta = closed_form_2(X,Y,0)\n",
    "\n",
    "print(\"L2 coeffcient:\",beta_L2)\n",
    "print(\"no punishment coefficient:\",beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see under L2 regularization, most of coefficient are shrinked compared to the no regularization formula, which can prevent overfiting, thus the linear model with L2 regularization is robust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. You can change the regularization parameter Œª to get different solutions for this problem. Suppose we set Œª = 10, 1, 0.1, 0.01, 0.001, and please evaluate the model R2 on the training set and the testing set. Finally, please decide the best regularization parameter $\\lambda$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\lambda$ = 0.01 is best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. From Problem 1, you can know which variables are significant, therefore you can use less variables to train model. For example, remove highly correlated and redundant features. You can propose a workflow to select feature.\n",
    "\n",
    "1. Remove the highly correlated variable first.\n",
    "2. Run regression, remove the insignificant variables step by step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient descent algorithm is an iterative process that takes us to the minimum of a function. Please write down the iterative expression for updating the solution of linear model and implement it using Python or Matlab in gradientDescent function.**\n",
    "* Batch based gradient descent iterative formula is$$\\beta_n = \\beta_{n-1} -\\frac{\\alpha}{m} X'(X\\beta -y)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final loss is  18.053454488251507\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Month      -0.255301\n",
       "MEI        -0.133413\n",
       "CO2        -0.039745\n",
       "CH4        -0.059796\n",
       "N2O         0.166380\n",
       "CFC-11      0.036993\n",
       "CFC-12      0.169644\n",
       "TSI         0.456629\n",
       "Aerosols    0.671386\n",
       "Constant    0.325425\n",
       "Name: correlation coefficient, dtype: float64"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "train_data = df_1.loc[:2006,:]\n",
    "\n",
    "def loss(coeff,x,y):\n",
    "    return (x@coeff-y).T@(x@coeff-y)\n",
    "\n",
    "def gradientDescent(x,y,iter_max=200000, batch=100,alpha=1e-5,\n",
    "                     min_gap=1e-1,constant=True):\n",
    "    record = []\n",
    "    if constant:\n",
    "        x[\"Constant\"]=1\n",
    "    columns = x.columns\n",
    "    x = np.matrix(x)\n",
    "    y = np.matrix(y).T\n",
    "    coeff = np.matrix(np.arange(x.shape[1])/x.shape[1]).T\n",
    "\n",
    "    for i in range(iter_max):\n",
    "        idx = np.random.choice(x.shape[0],batch)\n",
    "        x_batch = x[idx,:]\n",
    "        y_batch = y[idx,:]\n",
    "        iteration = alpha/batch*(x_batch.T@(x_batch@coeff-y_batch))\n",
    "        if np.abs(iteration.A1).all() < min_gap:\n",
    "            print(\"iteration terminal at %s times\"%i)\n",
    "            break\n",
    "        else:\n",
    "            coeff = coeff - iteration\n",
    "            record.append(loss(coeff,x,y)[0,0])\n",
    "            \n",
    "    plt.plot(record, label = \"loss_function\")\n",
    "    plt.ylabel(\"total_loss\")\n",
    "    plt.xlabel(\"iter_times\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"The final loss is \", record[-1])\n",
    "    result = pd.Series(coeff.A1, index=columns, name=\"correlation coefficient\")\n",
    "    return result\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "scaled_train = min_max_scaler.fit_transform(train_data.iloc[:,1:].values)\n",
    "scaled_train = pd.DataFrame(scaled_train, columns = train_data.columns[1:])\n",
    "result = gradientDescent(scaled_train.iloc[:,:-1], scaled_train.Temp)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
